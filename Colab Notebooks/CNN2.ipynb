{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN2.ipynb","provenance":[],"authorship_tag":"ABX9TyMLxEH4F3JI1b7Y5Bamuwd1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7i9iJQdqbyJI","executionInfo":{"status":"ok","timestamp":1661172024869,"user_tz":-330,"elapsed":2051,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"}},"outputId":"643e4fb1-939f-4eca-fedc-859fe006eff6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters \n","num_epochs = 15\n","batch_size = 8\n","learning_rate = 0.01\n","\n","# dataset has PILImage images of range [0, 1]. \n","# We transform them to Tensors of normalized range [-1, 1]\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                          shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n","                                         shuffle=False)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","source":["train_dataset.data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myZl8j0_hWup","executionInfo":{"status":"ok","timestamp":1661172024870,"user_tz":-330,"elapsed":10,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"}},"outputId":"a182f973-f0ba-4c51-bc8d-2deb4984bd49"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        # -> n, 3, 32, 32\n","        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n","        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n","        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n","        x = F.relu(self.fc1(x))               # -> n, 120\n","        x = F.relu(self.fc2(x))               # -> n, 84\n","        x = self.fc3(x)                       # -> n, 10\n","        return x\n"],"metadata":{"id":"hWD_eKb_b6Va","executionInfo":{"status":"ok","timestamp":1661172024871,"user_tz":-330,"elapsed":9,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["model = ConvNet().to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"metadata":{"id":"fhCBdknqcBhS","executionInfo":{"status":"ok","timestamp":1661172024872,"user_tz":-330,"elapsed":9,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["n_total_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n","        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 2000 == 0:\n","            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n","\n","print('Finished Training')\n","PATH = './cnn.pth'\n","torch.save(model.state_dict(), PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ozylx7zhccnj","executionInfo":{"status":"ok","timestamp":1661172348749,"user_tz":-330,"elapsed":323886,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"}},"outputId":"fabae51c-1662-47a1-ce5a-2243f507f70f"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/15], Step [2000/6250], Loss: 1.8560\n","Epoch [1/15], Step [4000/6250], Loss: 1.8286\n","Epoch [1/15], Step [6000/6250], Loss: 1.4149\n","Epoch [2/15], Step [2000/6250], Loss: 2.4808\n","Epoch [2/15], Step [4000/6250], Loss: 1.4274\n","Epoch [2/15], Step [6000/6250], Loss: 1.0468\n","Epoch [3/15], Step [2000/6250], Loss: 1.3828\n","Epoch [3/15], Step [4000/6250], Loss: 1.2506\n","Epoch [3/15], Step [6000/6250], Loss: 1.7517\n","Epoch [4/15], Step [2000/6250], Loss: 0.8761\n","Epoch [4/15], Step [4000/6250], Loss: 0.5670\n","Epoch [4/15], Step [6000/6250], Loss: 1.4666\n","Epoch [5/15], Step [2000/6250], Loss: 0.6261\n","Epoch [5/15], Step [4000/6250], Loss: 1.0484\n","Epoch [5/15], Step [6000/6250], Loss: 1.1642\n","Epoch [6/15], Step [2000/6250], Loss: 1.1636\n","Epoch [6/15], Step [4000/6250], Loss: 1.1091\n","Epoch [6/15], Step [6000/6250], Loss: 1.1780\n","Epoch [7/15], Step [2000/6250], Loss: 1.2199\n","Epoch [7/15], Step [4000/6250], Loss: 1.1127\n","Epoch [7/15], Step [6000/6250], Loss: 0.9873\n","Epoch [8/15], Step [2000/6250], Loss: 1.3054\n","Epoch [8/15], Step [4000/6250], Loss: 0.6516\n","Epoch [8/15], Step [6000/6250], Loss: 1.3159\n","Epoch [9/15], Step [2000/6250], Loss: 0.7417\n","Epoch [9/15], Step [4000/6250], Loss: 0.1924\n","Epoch [9/15], Step [6000/6250], Loss: 2.1428\n","Epoch [10/15], Step [2000/6250], Loss: 0.4995\n","Epoch [10/15], Step [4000/6250], Loss: 0.9562\n","Epoch [10/15], Step [6000/6250], Loss: 0.6654\n","Epoch [11/15], Step [2000/6250], Loss: 0.8494\n","Epoch [11/15], Step [4000/6250], Loss: 0.5747\n","Epoch [11/15], Step [6000/6250], Loss: 0.7723\n","Epoch [12/15], Step [2000/6250], Loss: 0.9255\n","Epoch [12/15], Step [4000/6250], Loss: 0.9149\n","Epoch [12/15], Step [6000/6250], Loss: 1.7260\n","Epoch [13/15], Step [2000/6250], Loss: 0.8512\n","Epoch [13/15], Step [4000/6250], Loss: 0.6974\n","Epoch [13/15], Step [6000/6250], Loss: 0.1356\n","Epoch [14/15], Step [2000/6250], Loss: 0.5557\n","Epoch [14/15], Step [4000/6250], Loss: 0.9000\n","Epoch [14/15], Step [6000/6250], Loss: 0.4228\n","Epoch [15/15], Step [2000/6250], Loss: 1.0693\n","Epoch [15/15], Step [4000/6250], Loss: 0.6954\n","Epoch [15/15], Step [6000/6250], Loss: 0.2488\n","Finished Training\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    n_class_correct = [0 for i in range(10)]\n","    n_class_samples = [0 for i in range(10)]\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        # max returns (value ,index)\n","        _, predicted = torch.max(outputs, 1)\n","        n_samples += labels.size(0)\n","        n_correct += (predicted == labels).sum().item()\n","        \n","        for i in range(batch_size):\n","            label = labels[i]\n","            pred = predicted[i]\n","            if (label == pred):\n","                n_class_correct[label] += 1\n","            n_class_samples[label] += 1\n","\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'Accuracy of the network: {acc} %')\n","\n","    for i in range(10):\n","        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n","        print(f'Accuracy of {classes[i]}: {acc} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxfk0P9odktJ","executionInfo":{"status":"ok","timestamp":1661172352010,"user_tz":-330,"elapsed":3273,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"}},"outputId":"b2c9bf0a-5e73-41cd-f917-2cab9d6fd32d"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network: 63.53 %\n","Accuracy of plane: 63.4 %\n","Accuracy of car: 78.1 %\n","Accuracy of bird: 53.7 %\n","Accuracy of cat: 46.9 %\n","Accuracy of deer: 49.0 %\n","Accuracy of dog: 49.9 %\n","Accuracy of frog: 75.9 %\n","Accuracy of horse: 67.8 %\n","Accuracy of ship: 79.6 %\n","Accuracy of truck: 71.0 %\n"]}]}]}