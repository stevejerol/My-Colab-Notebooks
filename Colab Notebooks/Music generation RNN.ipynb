{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6424,"status":"ok","timestamp":1665654430820,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"17gXajxj0JFm","outputId":"7070a4ab-4adc-4d23-ea7b-68b06d700461"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mitdeeplearning\n","  Downloading mitdeeplearning-0.2.0.tar.gz (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (1.21.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (4.64.1)\n","Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (0.25.2)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym-\u003emitdeeplearning) (1.5.0)\n","Requirement already satisfied: importlib-metadata\u003e=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym-\u003emitdeeplearning) (5.0.0)\n","Requirement already satisfied: gym-notices\u003e=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym-\u003emitdeeplearning) (0.0.8)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.8.0-\u003egym-\u003emitdeeplearning) (4.1.1)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.8.0-\u003egym-\u003emitdeeplearning) (3.9.0)\n","Building wheels for collected packages: mitdeeplearning\n","  Building wheel for mitdeeplearning (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mitdeeplearning: filename=mitdeeplearning-0.2.0-py3-none-any.whl size=2115442 sha256=29d14c40ab6e3bd06a87e62bfea6124090eea674c27f3f3d59436c6cddb9e5a7\n","  Stored in directory: /root/.cache/pip/wheels/9a/b9/4f/99b7c8c5c75355550b83e1fcfc02956fb40c35eb01e2262877\n","Successfully built mitdeeplearning\n","Installing collected packages: mitdeeplearning\n","Successfully installed mitdeeplearning-0.2.0\n"]}],"source":["!pip install mitdeeplearning"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":15199,"status":"ok","timestamp":1665654446016,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"43D7AlXA3Fzk"},"outputs":[],"source":["!apt-get install abcmidi timidity \u003e /dev/null 2\u003e\u00261"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4109,"status":"ok","timestamp":1665654450104,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"NHQBpegF0c9c"},"outputs":[],"source":["import mitdeeplearning as mdl"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1665654450105,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"DxjrgJc98JjK"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1665654450106,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"7jH9ybRz1Y92","outputId":"36730911-1233-45fd-a0bb-f451a2c13d38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 817 songs in text\n"]}],"source":["songs = mdl.lab1.load_training_data()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1665654450106,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"_kyWPEG-1eyS","outputId":"cb452e23-4216-46b6-f10a-6d99acbf0020"},"outputs":[{"name":"stdout","output_type":"stream","text":["Example song:\n","X:1\n","T:Alexander's\n","Z: id:dc-hornpipe-1\n","M:C|\n","L:1/8\n","K:D Major\n","(3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dcB A2 (3ABc|!\n","dAFA DFAd|fdcd FAdf|gfge fefd|(3efe dc d2:|!\n","AG|FAdA FAdA|GBdB GBdB|Acec Acec|dfaf gecA|!\n","FAdA FAdA|GBdB GBdB|Aceg fefd|(3efe dc d2:|!\n"]}],"source":["example_song = songs[0]\n","print(\"Example song:\")\n","print(example_song)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1665654450107,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"IbWZ1_S41ujj"},"outputs":[],"source":["#mdl.lab1.play_song(example_song)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1665654450107,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"Y8ePECzc2IH5","outputId":"a3e96302-4e73-44ef-b914-39e1ac1de59e"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 83 unique characters in the dataset\n"]}],"source":["# Join our list of song strings into a single string containing all songs\n","songs_joined = \"\\n\\n\".join(songs) \n","\n","# Find all unique characters in the joined string\n","vocab = sorted(set(songs_joined))\n","print(\"There are\", len(vocab), \"unique characters in the dataset\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1665654450108,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"1y358RN_2INF"},"outputs":[],"source":["### Define numerical representation of text ###\n","\n","# Create a mapping from character to unique index.\n","# For example, to get the index of the character \"d\", \n","#   we can evaluate `char2idx[\"d\"]`.  \n","char2idx = {u:i for i, u in enumerate(vocab)}\n","\n","# Create a mapping from indices to characters. This is\n","#   the inverse of char2idx and allows us to convert back\n","#   from unique index to the character in our vocabulary.\n","idx2char = np.array(vocab)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1665654450108,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"_mogRppI8Sli","outputId":"b29777a5-4a0a-4885-d728-6d83900731da"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  '\\n':   0,\n","  ' ' :   1,\n","  '!' :   2,\n","  '\"' :   3,\n","  '#' :   4,\n","  \"'\" :   5,\n","  '(' :   6,\n","  ')' :   7,\n","  ',' :   8,\n","  '-' :   9,\n","  '.' :  10,\n","  '/' :  11,\n","  '0' :  12,\n","  '1' :  13,\n","  '2' :  14,\n","  '3' :  15,\n","  '4' :  16,\n","  '5' :  17,\n","  '6' :  18,\n","  '7' :  19,\n","  ...\n","}\n"]}],"source":["print('{')\n","for char,_ in zip(char2idx, range(20)):\n","    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n","print('  ...\\n}')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1665654450109,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"Rr2TDiYw9QCb"},"outputs":[],"source":["def vectorize_string(string):\n","    vectorized_list = np.array([char2idx[s] for s in string])\n","    return vectorized_list\n","\n","vectorized_songs = vectorize_string(songs_joined)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1665654450109,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"T-RkpewX9bdK","outputId":"c8958f52-c80c-485d-a075-abe791410ffe"},"outputs":[{"name":"stdout","output_type":"stream","text":["'X:1\\nT:Alex' ---- characters mapped to int ----\u003e [49 22 13  0 45 22 26 67 60 79]\n"]}],"source":["print ('{} ---- characters mapped to int ----\u003e {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n","# check that vectorized_songs is a numpy array\n","assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1665654450109,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"ttMmj-oq9m_0","outputId":"2c3b342f-c4f3-481d-8e8a-876f9a6f04cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["[PASS] test_batch_func_types\n","[PASS] test_batch_func_shapes\n","[PASS] test_batch_func_next_step\n","======\n","[PASS] passed all tests!\n"]}],"source":["def get_batch(vectorized_songs, seq_length, batch_size):\n","  # the length of the vectorized songs string\n","  n = vectorized_songs.shape[0] - 1\n","  \n","  # randomly choose the starting indices for the examples in the training batch\n","  idx = np.random.choice(n-seq_length, batch_size)\n","  \n","\n","  '''TODO: construct a list of input sequences for the training batch'''\n","  input_batch = [vectorized_songs[i:i+seq_length] for i in idx]\n","  '''TODO: construct a list of output sequences for the training batch'''\n","  output_batch = [vectorized_songs[i+1: i+1+seq_length] for i in idx]\n","  \n","  # x_batch, y_batch provide the true inputs and targets for network training\n","  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n","  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n","  \n","  return x_batch, y_batch\n","\n","\n","# Perform some simple tests to make sure your batch function is working properly! \n","test_args = (vectorized_songs, 10, 2)\n","if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n","   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n","   not mdl.lab1.test_batch_func_next_step(get_batch, test_args): \n","   print(\"======\\n[FAIL] could not pass tests\")\n","else: \n","   print(\"======\\n[PASS] passed all tests!\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1665654450110,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"AlqdADZEGI6p","outputId":"bd2184e8-cc79-4461-9a7d-3af329668cf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Step   0\n","  input: 62 ('g')\n","  expected output: 60 ('e')\n","Step   1\n","  input: 60 ('e')\n","  expected output: 59 ('d')\n","Step   2\n","  input: 59 ('d')\n","  expected output: 27 ('B')\n","Step   3\n","  input: 27 ('B')\n","  expected output: 1 (' ')\n","Step   4\n","  input: 1 (' ')\n","  expected output: 32 ('G')\n"]}],"source":["x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n","\n","for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n","    print(\"Step {:3d}\".format(i))\n","    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n","    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1665654450110,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"TBJE5q6qIxWn"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1665654450110,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"QN1qDXXwHECD"},"outputs":[],"source":["def LSTM(rnn_units): \n","  return tf.keras.layers.LSTM(\n","    rnn_units, \n","    return_sequences=True, \n","    recurrent_initializer='glorot_uniform',\n","    recurrent_activation='sigmoid',\n","    stateful=True,\n","  )"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":562,"status":"ok","timestamp":1665654450651,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"YfpX2gl6Itbi"},"outputs":[],"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    # Layer 1: Embedding layer to transform indices into dense vectors \n","    #   of a fixed embedding size\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n","\n","    # Layer 2: LSTM with `rnn_units` number of units. \n","    LSTM(rnn_units),\n","\n","    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n","    #   into the vocabulary size. \n","    tf.keras.layers.Dense(units=vocab_size)\n","  ])\n","\n","  return model\n","\n","# Build a simple model with default hyperparameters. You will get the \n","#   chance to change these later.\n","model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1665654450652,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"k5liFhzYJCVC","outputId":"a73f07e1-5e77-471c-fb11-306fc96f4434"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (32, None, 256)           21248     \n","                                                                 \n"," lstm (LSTM)                 (32, None, 1024)          5246976   \n","                                                                 \n"," dense (Dense)               (32, None, 83)            85075     \n","                                                                 \n","=================================================================\n","Total params: 5,353,299\n","Trainable params: 5,353,299\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665654450653,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"OIyXEcGabwD6"},"outputs":[],"source":["X,y = get_batch(vectorized_songs, 16,32)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665654450653,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"VG1YJUaicRqt"},"outputs":[],"source":["prediction = model(X)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1160,"status":"ok","timestamp":1665654451805,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"nw2n3y0xdFtb","outputId":"a4172420-7e9c-42fa-e877-1b43c3244388"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 16)\n","(32, 16, 83)\n"]}],"source":["print(X.shape)\n","print(prediction.shape)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1665654451806,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"9WXLrjL6fAr7","outputId":"4341b7b4-e118-4739-a697-e0f793ba02e6"},"outputs":[{"data":{"text/plain":["array([78, 70, 11, 26, 56, 77, 73, 45, 70, 15, 15, 66, 15,  1, 45, 78])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["sampled_indices = tf.random.categorical(prediction[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n","sampled_indices"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1665654451806,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"yO7tU05UiAB9","outputId":"4257798c-3278-4235-a1e2-ea3fdc6e1154"},"outputs":[{"name":"stdout","output_type":"stream","text":["'wo/AavrTo33k3 Tw'\n"]}],"source":["print(repr(\"\".join(idx2char[sampled_indices])))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1665654451806,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"Cz791UnOi9sP","outputId":"3f2632be-2433-4e34-8df9-89ce1521f5ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 16)\n","4.4180593\n"]}],"source":["def loss_func(label,logits):\n","  loss = tf.keras.losses.sparse_categorical_crossentropy(label,logits,from_logits=True)\n","  return loss\n","\n","loss=loss_func(y,prediction)\n","print(loss.shape)\n","print(loss.numpy().mean())"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665654451807,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"kvlawRh2lzJc"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665654451808,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"SCMxKN6XkJg8"},"outputs":[],"source":["num_training_iterations = 5000  # Increase this to train longer\n","batch_size = 4  # Experiment between 1 and 64\n","seq_length = 250  # Experiment between 50 and 500\n","learning_rate = 1e-2  # Experiment between 1e-5 and 1e-1\n","\n","# Model parameters: \n","vocab_size = len(vocab)\n","embedding_dim = 256 \n","rnn_units = 2048  # Experiment between 1 and 2048\n","\n","# Checkpoint location: \n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1665654451809,"user":{"displayName":"Steve Jerome Lawrence","userId":"08735289231416543482"},"user_tz":-330},"id":"QQOgsF7uo8Im"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"5T4pbEqCl2ux","outputId":"ff783c55-1dfb-446b-d394-1e3fc4af9a53"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 1/5000 [00:53\u003c74:49:19, 53.88s/it]"]}],"source":["'''TODO: instantiate a new model for training using the `build_model`\n","  function and the hyperparameters created above.'''\n","model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n","\n","'''TODO: instantiate an optimizer with its learning rate.\n","  Checkout the tensorflow website for a list of supported optimizers.\n","  https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/\n","  Try using the Adam optimizer to start.'''\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","@tf.function\n","def train_step(x, y): \n","  # Use tf.GradientTape()\n","  with tf.GradientTape() as tape:\n","  \n","    '''TODO: feed the current input into the model and generate predictions'''\n","    y_hat = model(x)\n","  \n","    '''TODO: compute the loss!'''\n","    loss = loss_func(y, y_hat)\n","\n","  # Now, compute the gradients \n","  '''TODO: complete the function call for gradient computation. \n","      Remember that we want the gradient of the loss with respect all \n","      of the model parameters. \n","      HINT: use `model.trainable_variables` to get a list of all model\n","      parameters.'''\n","  grads = tape.gradient(loss, model.trainable_variables)\n","  \n","  # Apply the gradients to the optimizer so it can update the model accordingly\n","  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","  return loss\n","\n","##################\n","# Begin training!#\n","##################\n","\n","history = []\n","plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n","if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n","\n","for iter in tqdm(range(num_training_iterations)):\n","\n","  # Grab a batch and propagate it through the network\n","  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n","  loss = train_step(x_batch, y_batch)\n","\n","  # Update the progress bar\n","  history.append(loss.numpy().mean())\n","  plotter.plot(history)\n","\n","  # Update the model with the changed weights!\n","  if iter % 100 == 0:     \n","    model.save_weights(checkpoint_prefix)\n","    \n","# Save the trained model and the weights\n","model.save_weights(checkpoint_prefix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVTV2K5fstqJ"},"outputs":[],"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","\n","# Restore the model weights for the last checkpoint after training\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1, None]))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-On7nLJsxdf"},"outputs":[],"source":["def generate_text(model, start_string, generation_length=1000):\n","  # Evaluation step (generating ABC text using the learned RNN model)\n","\n","  '''TODO: convert the start string to numbers (vectorize)'''\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Empty string to store our results\n","  text_generated = []\n","\n","  # Here batch size == 1\n","  model.reset_states()\n","  tqdm._instances.clear()\n","\n","  for i in tqdm(range(generation_length)):\n","      predictions = model(input_eval)\n","      \n","      # Remove the batch dimension\n","      predictions = tf.squeeze(predictions, 0)\n","      \n","      '''TODO: use a multinomial distribution to sample'''\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","      \n","      # Pass the prediction along with the previous hidden state\n","      #   as the next inputs to the model\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","      \n","      '''TODO: add the predicted character to the generated text!'''\n","      # Hint: consider what format the prediction is in vs. the output\n","      text_generated.append(idx2char[predicted_id])\n","    \n","  return (start_string + ''.join(text_generated))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPvqiU9YtYL2"},"outputs":[],"source":["generated_text = generate_text(model, start_string=\"X\", generation_length=1000) # TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHx_1gC3t39z"},"outputs":[],"source":["from IPython import display as ipythondisplay"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1U5otMLYAgrQvVM_rhP25cI11XbbiF-8I"},"id":"PxT2s8Frt1nC","outputId":"aa0d6177-90dc-4fc3-8c24-248ae8efb89a"},"outputs":[],"source":["### Play back generated songs ###\n","\n","generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n","\n","for i, song in enumerate(generated_songs): \n","  # Synthesize the waveform from a song\n","  waveform = mdl.lab1.play_song(song)\n","\n","  # If its a valid song (correct syntax), lets play it! \n","  if waveform:\n","    print(\"Generated song\", i)\n","    ipythondisplay.display(waveform)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMKxpKQ9lF2uikCCNxdWP5A","collapsed_sections":[],"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}